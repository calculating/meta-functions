{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(tasks, sampl, dimsx, dimsy):\n",
    "    x = tf.random.normal([tasks, sampl, dimsx])\n",
    "    \n",
    "    Wo = tf.Variable(tf.random.normal([tasks, dimsx, dimsy]))\n",
    "    bo = tf.Variable(tf.random.normal([tasks, 1, dimsy]))\n",
    "    y = tf.nn.sigmoid(tf.add(tf.matmul(x, Wo), bo))\n",
    "    \n",
    "    l = y[:, -1, :]\n",
    "    y = tf.concat([y[:, :-1, :], tf.zeros(bo.shape)], axis=1)\n",
    "    return tf.concat([x, y], axis=2), l\n",
    "\n",
    "def datagen_layered(tasks, sampl, dimsx, dimsy):\n",
    "    x = tf.random.normal([tasks, sampl, dimsx])\n",
    "    W1 = tf.Variable(tf.random.normal([tasks, dimsx, 5]))\n",
    "    b1 = tf.Variable(tf.random.normal([tasks, 1, 5]))\n",
    "    x1 = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))\n",
    "\n",
    "    W2 = tf.Variable(tf.random.normal([tasks, 5, 10]))\n",
    "    b2 = tf.Variable(tf.random.normal([tasks, 1, 10]))\n",
    "    x2 = tf.nn.relu(tf.add(tf.matmul(x1, W2), b2))\n",
    "\n",
    "    W3 = tf.Variable(tf.random.normal([tasks, 10, 4]))\n",
    "    b3 = tf.Variable(tf.random.normal([tasks, 1, 4]))\n",
    "    x3 = tf.nn.relu(tf.add(tf.matmul(x2, W3), b3))\n",
    "    \n",
    "    Wo = tf.Variable(tf.random.normal([tasks, 4, dimsy]))\n",
    "    bo = tf.Variable(tf.random.normal([tasks, 1, dimsy]))\n",
    "    y = tf.nn.sigmoid(tf.add(tf.matmul(x3, Wo), bo))\n",
    "    \n",
    "    l = y[:, -1, :]\n",
    "    y = tf.concat([y[:, :-1, :], tf.zeros(bo.shape)], axis=1)\n",
    "    return tf.concat([x, y], axis=2), l\n",
    "\n",
    "def datagen_wide(tasks, sampl, dimsx, dimsy):\n",
    "    x = tf.random.normal([tasks, sampl, dimsx])\n",
    "    W1 = tf.Variable(tf.random.normal([tasks, dimsx, 20]))\n",
    "    b1 = tf.Variable(tf.random.normal([tasks, 1, 20]))\n",
    "    x1 = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))\n",
    "    \n",
    "    Wo = tf.Variable(tf.random.normal([tasks, 20, dimsy]))\n",
    "    bo = tf.Variable(tf.random.normal([tasks, 1, dimsy]))\n",
    "    y = tf.nn.sigmoid(tf.add(tf.matmul(x1, Wo), bo))\n",
    "    \n",
    "    l = y[:, -1, :]\n",
    "    y = tf.concat([y[:, :-1, :], tf.zeros(bo.shape)], axis=1)\n",
    "    return tf.concat([x, y], axis=2), l\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all Transformers have a key, value, and query size of 32, 8 heads, and 4 layers, and model size of NM = 256. The model size defines the dimensionality of each token, and the MLP between layers scales this size up to a hidden representation of 4 Ã— NM where NM corresponds to the model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = layers.MultiHeadAttention(**kwargs)\n",
    "    # self.layernorm = layers.LayerNormalization()\n",
    "    self.add = layers.Add()\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    # x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class FeedForward(layers.Layer):\n",
    "  def __init__(self, d_model, dff):\n",
    "    super().__init__()\n",
    "    self.seq = models.Sequential([\n",
    "      layers.Dense(dff, activation='relu'),\n",
    "      layers.Dense(d_model)\n",
    "    ])\n",
    "    self.add = layers.Add()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    return x\n",
    "\n",
    "class TransformLayer(layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n",
    "\n",
    "class Transformer(models.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layerstack = [TransformLayer(d_model=d_model, num_heads=num_heads, dff=dff) for _ in range(num_layers)]\n",
    "\n",
    "  def call(self, x):\n",
    "    for layer in self.layerstack:\n",
    "      x = layer(x)\n",
    "    x = tf.nn.sigmoid(x)\n",
    "    return x[:, -1, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl = 100\n",
    "dx = 15\n",
    "dy = 1\n",
    "\n",
    "mdim = dx + dy\n",
    "head = 2\n",
    "mlay = 2\n",
    "assert mdim % head == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 11:32:28.046443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-30 11:32:28.291454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 11:33:01.990966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-30 11:33:02.230537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 11:33:35.674864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-30 11:33:35.927144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\r"
     ]
    }
   ],
   "source": [
    "\n",
    "gpicl_standard = Transformer(num_layers=mlay, d_model=mdim, num_heads=head, dff=mdim*4)\n",
    "gpicl_layered = Transformer(num_layers=mlay, d_model=mdim, num_heads=head, dff=mdim*4)\n",
    "gpicl_wide = Transformer(num_layers=mlay, d_model=mdim, num_heads=head, dff=mdim*4)\n",
    "\n",
    "class DisplayProgress(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, eps), end='\\r')\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "opt = optimizers.SGD(learning_rate=0.01)\n",
    "gpicl_standard.compile(optimizer=opt, loss=loss_fn, metrics=['mae'])\n",
    "gpicl_layered.compile(optimizer=opt, loss=loss_fn, metrics=['mae'])\n",
    "gpicl_wide.compile(optimizer=opt, loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "eps = 200\n",
    "\n",
    "train_s_standard, train_l_standard = datagen(400, sampl, dx, dy)\n",
    "valid_s_standard, valid_l_standard = datagen(100, sampl, dx, dy)\n",
    "train_s_layered, train_l_layered = datagen_layered(400, sampl, dx, dy)\n",
    "valid_s_layered, valid_l_layered = datagen_layered(100, sampl, dx, dy)\n",
    "train_s_wide, train_l_wide = datagen_wide(400, sampl, dx, dy)\n",
    "valid_s_wide, valid_l_wide = datagen_wide(100, sampl, dx, dy)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    gpicl_standard.fit(train_s_standard, train_l_standard, epochs=eps, batch_size=100, validation_data=(valid_s, valid_l), callbacks=[tensorboard_callback, DisplayProgress()], verbose=0)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    gpicl_layered.fit(train_s_layered, train_l_layered, epochs=eps, batch_size=100, validation_data=(valid_s, valid_l), callbacks=[tensorboard_callback, DisplayProgress()], verbose=0)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    gpicl_wide.fit(train_s_wide, train_l_wide, epochs=eps, batch_size=100, validation_data=(valid_s, valid_l), callbacks=[tensorboard_callback, DisplayProgress()], verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4940679\n",
      "0.42865488\n",
      "Model: \"transformer_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transform_layer_208 (Transf  multiple                 4288      \n",
      " ormLayer)                                                       \n",
      "                                                                 \n",
      " transform_layer_209 (Transf  multiple                 4288      \n",
      " ormLayer)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_mean(train_l).numpy())\n",
    "print(tf.math.reduce_std(train_l).numpy())\n",
    "\n",
    "tf.summary.histogram(\n",
    "    'labels', train_l\n",
    ")\n",
    "\n",
    "gpicl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.47471383, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_mean(tf.math.abs(train_l[:1000] - valid_l)))\n",
    "for i in range(20, 50):\n",
    "    print(valid_l[i].numpy(), gpicl(valid_s[i:i+1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f8a38f5af8d85e4d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f8a38f5af8d85e4d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
